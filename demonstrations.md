[ [neoRL](index) ]   [ [demonstration](demonstrations.md) ]     [ [about the author](./about_the_author.md) ]

-----------------------------------------------------

## Real-time learning videos
Autonomous navigation happens in the allocentric [WaterWorld](https://pygame-learning-environment.readthedocs.io/en/latest/user/games/waterworld.html) environment (not the simpler egocentric javascript-version). 
Learning and execution happens in real-time in the following videos, with the agent being initiated at the beginning of the run (video) with no precursors other than what is described in the above article. 

<iframe width="560" height="315" src="https://www.youtube.com/embed/ZyvxaMnm92s" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

------------------------------------------
A video of recursive desire, a demonstration of category II autonomy. 
Agent design is illustrated in the figure on the left.

<iframe src="https://player.vimeo.com/video/684966970?h=aec1b78a82&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen style="position:absolute;top:0;left:0;width:100%;height:100%;" title="The neoRL framework for autonomous navigation."></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

----
